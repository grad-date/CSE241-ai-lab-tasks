{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "morph_analysis_middle-high-german.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnNKhAvS9hOb"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch \n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "\n",
        "SEED = 1\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xhdQGzM9sEd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C4ALsTg9w9Y"
      },
      "source": [
        "file_name = 'middle-high-german-train-low'\n",
        "evaluate_file = 'middle-high-german-dev'\n",
        "test_file = 'middle-high-german-test'\n",
        "\n",
        "def file_preprocess(file_name):\n",
        "    \n",
        "    # from google.colab import files\n",
        "    # uploaded = files.upload()\n",
        "    \n",
        "    pandas_holder = pd.read_csv(file_name, sep='\\t', names=['word', 'inflection', 'feature'])\n",
        "    \n",
        "    words_list = [list(word) for word in list(pandas_holder['word'])]\n",
        "    inflection_list = [list(inflection) for inflection in list(pandas_holder['inflection'])]\n",
        "    feature_list = [feat.split(';') for feat in list(pandas_holder['feature'])]\n",
        "    #print(words_list);\n",
        "\n",
        "    vocab_chars_word = [char for word in words_list for char in word]\n",
        "    vocab_chars_inflection = [char for word in inflection_list for char in word]\n",
        "    # print(vocab_chars_word)\n",
        "\n",
        "    char_vocab = ['<pad>', '<sos>', '<eos>'] + list(set(vocab_chars_word+vocab_chars_inflection))\n",
        "    feat_vocab = ['<pad>'] + list(set([f for feat in feature_list for f in feat]))\n",
        "\n",
        "    # print(char_vocab)\n",
        "    char_to_index = dict(zip(char_vocab, list(range(len(char_vocab)))))\n",
        "    index_to_char = dict(zip(list(range(len(char_vocab))), char_vocab))\n",
        "    feature_to_index = dict(zip(feat_vocab, list(range(len(feat_vocab)))))\n",
        "\n",
        "    # 2 added here b/c sos and eos appended to each word and inflection word\n",
        "    word_list_length = [len(word)+2 for word in words_list]\n",
        "    inflection_list_length = [len(word)+2 for word in inflection_list]\n",
        "    feature_list_length = [len(feat) for feat in feature_list]\n",
        "\n",
        "    max_word_length = max(word_list_length)\n",
        "    max_inflection_length = max(inflection_list_length)\n",
        "    max_feature_length = max(feature_list_length)\n",
        "\n",
        "    return words_list, inflection_list, feature_list, char_to_index, index_to_char, feature_to_index, max_word_length, max_inflection_length, max_feature_length\n",
        "\n",
        "def boundary_appender(sentence_list):\n",
        "    sent_list = []\n",
        "    for sentence in sentence_list:\n",
        "        sentence.append('<eos>')\n",
        "        sentence.insert(0,'<sos>')\n",
        "        sent_list.append(sentence)\n",
        "    return sent_list\n",
        "\n",
        "def sentence_pad(sentence_list, length):\n",
        "    sent_list = []\n",
        "    for sentence in sentence_list:\n",
        "        while len(sentence) != length:\n",
        "            sentence.append(char_to_index['<pad>'])\n",
        "        sent_list.append(sentence)\n",
        "    return sent_list\n",
        "\n",
        "def word_pad(word, length):\n",
        "    while len(word) != length:\n",
        "        word.append(char_to_index['<pad>'])\n",
        "    return word\n",
        "\n",
        "def source_taget_equal_length_maker(source, target):\n",
        "    source_lengths = [len(s) for s in source]\n",
        "    target_lengths = [len(t) for t in target]\n",
        "    max_lengths = max(max(source_lengths), max(target_lengths))\n",
        "\n",
        "    source_sent = sentence_pad(source, max_lengths)\n",
        "    target_sent = sentence_pad(target, max_lengths)\n",
        "    return source_sent, target_sent, max_lengths\n",
        "\n",
        "def sentence_encoder(sentence_list, dictionary):\n",
        "    sent_list = [[dictionary[word] for word in sentence]for sentence in sentence_list]\n",
        "    return sent_list\n",
        "\n",
        "def mini_batch_creator(sentence_list, batch_size):\n",
        "    final = [sentence_list[i * batch_size:(i + 1) * batch_size] for i in range((len(sentence_list) + batch_size - 1) // batch_size)]\n",
        "    return final\n",
        "\n",
        "\"\"\"**Encoder Class**\"\"\"\n",
        "\n",
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_size, encoder_hid_dem,decoder_hid_dem,bidirectional,device):\n",
        "        super().__init__()\n",
        "        # super(EncoderLSTM, self).__init__()\n",
        "        self.encoder_hid_dem  = encoder_hid_dem\n",
        "        self.encoder_n_direction=1;\n",
        "        self.device = device\n",
        "        self.bias = False\n",
        "        if(bidirectional==True):\n",
        "            self.encoder_n_direction=2;\n",
        "\n",
        "        self.embedding_layer  = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size, padding_idx=0)\n",
        "        self.GRU_layer        = nn.GRU(input_size=embedding_size, hidden_size=encoder_hid_dem, batch_first=True, bidirectional=bidirectional)\n",
        "        self.fc               = nn.Linear(encoder_hid_dem*self.encoder_n_direction,decoder_hid_dem)\n",
        "        #self.GRU_layer.bias   = torch.nn.Parameter(torch.zeros(encoder_hid_dem))\n",
        "\n",
        "\n",
        "    def forward(self, input_word):\n",
        "        # print(input_word.size())\n",
        "        #[batch_size    src_sent_lent]\n",
        "\n",
        "        embed_out = self.embedding_layer(input_word)\n",
        "        #[BATCH_SIZE    src_sent_lent   embedding_dim]\n",
        "        \n",
        "        embed_out = F.relu(embed_out)\n",
        "        embed_out = F.dropout(embed_out, p=0.5)\n",
        "\n",
        "        self.batch = embed_out.size()[0]\n",
        "\n",
        "        # hidden = self.init_hidden()\n",
        "        GRU_out,hidden = self.GRU_layer(embed_out)\n",
        "\n",
        "        \n",
        "        # print(GRU_out.size())\n",
        "        # print(hidd.size())\n",
        "\n",
        "        #[BATCH_SIZE    sec_sent_len    n_direction*hid_dem]\n",
        "        #[n_layer*n_direction   batch_size    hid_dem]\n",
        "\n",
        "        #where the first hid_dim elements in the third axis are the hidden states from the top layer forward RNN, and the last hid_dim elements are hidden states from the top layer backward RNN\n",
        "\n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "\n",
        "        GRU_out = F.relu(GRU_out)\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)))\n",
        "        \n",
        "        # print(GRU_out.size())\n",
        "        # print(hidden.size())\n",
        "\n",
        "        #outputs = [batch_size    src sent len, encoder_hid_dim * n_direction]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        return GRU_out,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (Variable(torch.eye(1, self.encoder_hid_dem)).unsqueeze(1).repeat(2, self.batch, 1).to(self.device))\n",
        "\n",
        "\"\"\"**Attention Class**\"\"\"\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,encoder_hid_dem,decoder_hid_dem,bidirectional):\n",
        "        super().__init__()\n",
        "        self.enc_hid_dim = encoder_hid_dem\n",
        "        self.dec_hid_dim = decoder_hid_dem\n",
        "        self.encoder_n_direction=1;\n",
        "        if(bidirectional==True):\n",
        "            self.encoder_n_direction=2;\n",
        "        self.attn = nn.Linear((encoder_hid_dem * self.encoder_n_direction) + decoder_hid_dem, decoder_hid_dem)\n",
        "        self.v = nn.Parameter(torch.rand(decoder_hid_dem))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [batch_size    ,src sent len, enc hid dim * encoder_n_direction]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        src_len    = encoder_outputs.shape[1]\n",
        "        \n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        #hidden          = [batch size, src sent len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * encoder_n_direction]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2))) \n",
        "        #energy = [batch size, src sent len, dec hid dim]\n",
        "        \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        #energy = [batch size, dec hid dim, src sent len]\n",
        "        \n",
        "        #v = [dec hid dim]\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        #v = [batch size, 1, dec hid dim]\n",
        "                \n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        #attention= [batch size, src len]\n",
        "        \n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\"\"\"**Decoder Class**\"\"\"\n",
        "\n",
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, decoder_hid_dem, encoder_hid_dem, vocab_size,embedding_dim,attention,decoder_input_size,linear_input_size,bidirectional,device):\n",
        "        super().__init__()      \n",
        "        self.encoder_hid_dem=encoder_hid_dem\n",
        "        self.decoder_hid_dem=decoder_hid_dem\n",
        "        self.attention=attention\n",
        "        self.device = device\n",
        "\n",
        "        self.decoder_n_direction=1;\n",
        "        if(bidirectional==True):\n",
        "            self.decoder_n_direction=2;\n",
        "        self.GRU_layer_out = nn.GRU(decoder_input_size,decoder_hid_dem)\n",
        "        self.out_layer = nn.Linear(in_features=linear_input_size, out_features=vocab_size)\n",
        "        #self.GRU_layer_out.bias = torch.nn.Parameter(torch.zeros(decoder_input_size))\n",
        "\n",
        "    def forward(self, feature, hidden,actual_word,encoder_outputs):\n",
        "\n",
        "        feature = feature.unsqueeze(1)\n",
        "        # print('decoder')\n",
        "        # print(feature.size())\n",
        "        #[batch_size    src_sent_lent=1   feat_size=6]\n",
        "       \n",
        "        # print(hidden.size())\n",
        "        # [batch_size     dec_hid_dim]\n",
        "\n",
        "\n",
        "        # print(actual_word.size())\n",
        "        # [batch_size    src_sent_lent=1   embedding_dim]\n",
        "\n",
        "        # print(encoder_outputs.size())\n",
        "        # outputs = [batch_size    src sent len, encoder_hid_dim * encoder_n_directional]\n",
        "\n",
        "\n",
        "        a = self.attention(hidden,encoder_outputs)\n",
        "        #  print(a.size())\n",
        "        # [batch_size    src_sent_len]\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "        #a = [batch size, 1, src len] \n",
        "\n",
        "        weighted = torch.bmm(a,encoder_outputs)\n",
        "        # print(weighted.size())\n",
        "        # weighted = [batch size, 1, enc_hid_dim * encoder_n_direction]\n",
        "        # if len(actual_word.size()) != 0:\n",
        "        input_char = torch.cat((actual_word,feature,weighted),2) \n",
        "        # else:\n",
        "        #     input_char = torch.cat((feature,weighted),2)\n",
        "\n",
        "        input_char=input_char.permute(1,0,2)\n",
        "        #  print(input_char.size())\n",
        "        # [1    BATCH_SIZE      decoder_input_size]\n",
        "\n",
        "        hidden = hidden.unsqueeze(0)\n",
        "        # print(hidden.size())\n",
        "        #[1 batch_size decoder_hid_dem]\n",
        "       \n",
        "        output, hidden = self.GRU_layer_out(input_char, hidden)\n",
        "\n",
        "        # print(output.size())\n",
        "        # [sent_len=1   batch_size  decoder_n_direction*decoder_hid_dem]\n",
        "        # print(hidden.size())\n",
        "        # [n_layer*n_direction    BATCH_SIZE      hid_dem]\n",
        "\n",
        "\n",
        "\n",
        "        output = F.leaky_relu(output)\n",
        "        output = F.dropout(output, p=0.5)\n",
        "\n",
        "        output = torch.cat((output.squeeze(0),weighted.squeeze(1),actual_word.squeeze(1)),dim=1)\n",
        "        pre_out = self.out_layer(output)\n",
        "        predicted_output = F.log_softmax(pre_out, dim=1)\n",
        "\n",
        "        # print(predicted_output.size())\n",
        "        # [ batch_size vacab_size ]\n",
        "        return predicted_output, hidden.squeeze(0)  \n",
        "\n",
        "    def init_hidden(self, batch):\n",
        "        return (Variable(torch.eye(1, self.decoder_hid_dem)).unsqueeze(1).repeat(1, batch, 1).to(self.device),Variable(torch.eye(1, self.decoder_hid_dem)).unsqueeze(1).repeat(1, batch, 1).to(self.device))\n",
        "\n",
        "\"\"\"**Ploatter Class**\"\"\"\n",
        "\n",
        "def ploatter(loss, acc, val_loss, val_acc):\n",
        "    fig = plt.figure()\n",
        "\n",
        "    # x axis values\n",
        "    x = list(range(1,len(loss)+1))\n",
        "    fig1=plt.figure(figsize=(18, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
        "    fig1=plt.subplot(1,2,1)\n",
        "\n",
        "    lines_1 = plt.plot(x, loss, x, val_loss)\n",
        "    l1, l2 = lines_1\n",
        "    plt.setp(lines_1, linestyle='--')\n",
        "    plt.setp(l1, linewidth=2, color='b', label='Train Loss')\n",
        "    plt.setp(l2, linewidth=2, color='g', label='Validation Loss')\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    fig1.set_title('Loss/Epoch')\n",
        "    fig1.set_xlabel('Epoch')\n",
        "    fig1.set_ylabel('loss')\n",
        "\n",
        "    fig2=plt.subplot(1, 2, 2)\n",
        "\n",
        "    lines_2 = plt.plot(x, acc, x, val_acc)\n",
        "    l1, l2 = lines_2\n",
        "    plt.setp(lines_2, linestyle='--')\n",
        "    plt.setp(l1, linewidth=2, color='b', label='Train Accuracy')\n",
        "    plt.setp(l2, linewidth=2, color='g', label='Validation Accuracy')\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    fig2.set_title('Accuracy/Epoch')\n",
        "    fig2.set_xlabel('Epoch')\n",
        "    fig2.set_ylabel('Accuracy')\n",
        "    \n",
        "    \n",
        "    fig.savefig(file_name+'.png')\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"**Training Model Class**\"\"\"\n",
        "\n",
        "def train_model(encoder, decoder, encoder_optimizer, decoder_optimizer, criteria, train_input_word, train_output_word, train_feature_words, max_word_length,device):\n",
        "\n",
        "\n",
        "    # print(train_input_word.size())\n",
        "    # print(train_feature_words.size())\n",
        "\n",
        "    batch_size = train_input_word.size()[0]\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    actual_word = encoder.embedding_layer(torch.tensor(char_to_index['<sos>']).view(1, -1).to(device)).repeat(batch_size, 1, 1)\n",
        "    # print(encoder.embedding_layer(torch.tensor(char_to_index['<sos>']).to(device)).size())\n",
        "    \n",
        "    encoder_outputs,hidden = encoder(train_input_word)\n",
        "\n",
        "    feature = train_feature_words[:, :]\n",
        "    \n",
        "    char_loss   = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    for idx in range(max_word_length):\n",
        "\n",
        "        predicted_output, hidden = decoder(feature, hidden,actual_word,encoder_outputs)\n",
        "\n",
        "        topv, topi = predicted_output.topk(1)\n",
        "        bs = topi.size()[0]\n",
        "        temp2 = torch.zeros(0,1,300).to(device)\n",
        "\n",
        "        for row in range(bs):\n",
        "            index = topi[row][0].item()\n",
        "            temp = encoder.embedding_layer(torch.tensor(index).view(1, -1).to(device))\n",
        "            temp2 = torch.cat((temp2,temp))\n",
        "\n",
        "        teacher_force = random.random() < .5\n",
        "        \n",
        "        if teacher_force == 1:\n",
        "            actual_word = encoder.embedding_layer(train_output_word[:,idx]).unsqueeze(1)\n",
        "        else:\n",
        "            actual_word = temp2\n",
        "        \n",
        "        # print(temp2.size())\n",
        "        # initial_word = encoder.embedding_layer(torch.tensor(char_to_index[index_to_char[topi.item()]]).view(1, -1).cuda())\n",
        "\n",
        "\n",
        "\n",
        "        predicted_label = torch.argmax(predicted_output, dim=1)\n",
        "        num_correct = (predicted_label == train_output_word[:, idx]).sum()\n",
        "        \n",
        "        running_acc += num_correct.item()\n",
        "        char_loss += criteria(predicted_output, train_output_word[:, idx])\n",
        "\n",
        "    char_loss.backward()\n",
        "    \n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return char_loss.item()/max_word_length, running_acc/(max_word_length*batch_size)\n",
        "\n",
        "\"\"\"**Validation Class**\"\"\"\n",
        "\n",
        "def validate_model(encoder, decoder, criteria, valid_input_word, valid_output_word, valid_feature_words, max_word_length,device):\n",
        "    batch_size = valid_input_word.size()[0]\n",
        "\n",
        "    initial_word = encoder.embedding_layer(torch.tensor(char_to_index['<sos>']).view(1, -1).to(device)).repeat(batch_size, 1, 1)\n",
        "\n",
        "    encoder_outputs,hidden = encoder(valid_input_word)\n",
        "    decoder_output = []\n",
        "\n",
        "    vali_char_loss = 0.0\n",
        "    vali_running_acc = 0.0\n",
        "  \n",
        "    feature = valid_feature_words[:, :]\n",
        "    act = torch.zeros(batch_size,max_word_length).to(device)\n",
        "  \n",
        "    for idx in range(max_word_length):\n",
        "\n",
        "        predicted_output, hidden = decoder(feature, hidden,initial_word,encoder_outputs)\n",
        "        # initial_word = encoder.embedding_layer(valid_output_word[:,idx]).unsqueeze(1)               \n",
        "        # topv, topi = predicted_output.data.topk(batch_size)\n",
        "        # initial_word = encoder.embedding_layer(torch.tensor(char_to_index[index_to_char[topi.item()]]).view(1, -1).to(device)).repeat(batch_size, 1, 1)\n",
        "\n",
        "        \n",
        "        topv, topi = predicted_output.topk(1)\n",
        "        bs = topi.size()[0]\n",
        "        temp2 = torch.zeros(0,1,300).to(device)\n",
        "\n",
        "        decoder_output.append(topi)\n",
        "\n",
        "        for row in range(bs):\n",
        "            index = topi[row][0].item()\n",
        "            act[row][idx] = index\n",
        "            temp = encoder.embedding_layer(torch.tensor(index).view(1, -1).to(device))\n",
        "            temp2 = torch.cat((temp2,temp))\n",
        "\n",
        "        initial_word = temp2\n",
        "\n",
        "        predicted_label = torch.argmax(predicted_output, dim=1)\n",
        "\n",
        "        num_correct = (predicted_label == valid_output_word[:, idx]).sum()\n",
        "        vali_running_acc += num_correct.item()\n",
        "        vali_char_loss += criteria(predicted_output, valid_output_word[:, idx])\n",
        "    \n",
        "    # for i in range(batch_size):\n",
        "    #   for j in range(max_word_length):\n",
        "    #     print(index_to_char[int(act[i][j].item())],end=\"\")\n",
        "    #   print('')\n",
        "    \n",
        "\n",
        "        \n",
        "    return vali_char_loss.item() / max_word_length, vali_running_acc / (max_word_length * batch_size)\n",
        "\n",
        "\"\"\"**Actual Training function**\"\"\"\n",
        "\n",
        "def train_iter(encoder, decoder, input_word, output_word, feat_encode_list, valid_word, valid_label, valid_feat,device,encoder_optimizer,decoder_optimizer, batch_size, epoch_size):\n",
        "    criteria = nn.NLLLoss()\n",
        "\n",
        "    input_word_minibatches  = mini_batch_creator(input_word, batch_size=batch_size)\n",
        "    output_word_minibatches = mini_batch_creator(output_word, batch_size=batch_size)\n",
        "    feature_minibatches     = mini_batch_creator(feat_encode_list, batch_size=batch_size)\n",
        "\n",
        "    # valid_word_minibatches  = mini_batch_creator(valid_word,batch_size=10)\n",
        "    # valid_label_minibatches = mini_batch_creator(valid_label,batch_size=10)\n",
        "    # valid_feat_minibatches  = mini_batch_creator(valid_feat,batch_size=10)\n",
        "\n",
        "    return_batch_loss, return_batch_acc = [], []\n",
        "    val_return_batch_loss, val_return_batch_acc = [], []\n",
        "\n",
        "    valid_word, valid_label, max_length_1 = source_taget_equal_length_maker(valid_word, valid_label)\n",
        "    valid_word = torch.tensor(valid_word).to(device)\n",
        "    valid_label = torch.tensor(valid_label).to(device)\n",
        "    valid_feat = torch.FloatTensor(valid_feat).to(device)\n",
        "\n",
        "    for epoch in range(epoch_size):\n",
        "\n",
        "        batch_loss, batch_acc = [], []\n",
        "        val_batch_loss, val_batch_acc = [], []\n",
        "\n",
        "        for batch_idx, _ in enumerate(input_word_minibatches):\n",
        "            train_word = input_word_minibatches[batch_idx]\n",
        "            train_label = output_word_minibatches[batch_idx]\n",
        "            train_feat = feature_minibatches[batch_idx]\n",
        "\n",
        "            train_word, train_label, max_length = source_taget_equal_length_maker(train_word, train_label)\n",
        "\n",
        "            train_word = torch.tensor(train_word).to(device)\n",
        "            train_label = torch.tensor(train_label).to(device)\n",
        "            train_feat = torch.FloatTensor(train_feat).to(device)\n",
        "\n",
        "            loss, accuracy = train_model(encoder, decoder, encoder_optimizer, decoder_optimizer, criteria, train_word, train_label, train_feat, max_length,device)\n",
        "\n",
        "            batch_loss.append(loss)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "\n",
        "            # print(\"Epoch: %d/%d\" %(epoch+1, epoch_size),\n",
        "            #       \"Batch: %d/%d\" %(batch_idx+1, len(input_word_minibatches)),\n",
        "            #       \"TrainLoss: %3f\" %(loss),\n",
        "            #       \"TrainAccuracy: %3f\" %(accuracy),\n",
        "            #       \"Avg_TrainLoss: %3f\" % (sum(batch_loss)/len(batch_loss)),\n",
        "            #       \"Avg_TrainAccuracy: %3f\" %(sum(batch_acc)/len(batch_acc)),)\n",
        "\n",
        "        return_batch_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "        return_batch_acc.append(sum(batch_acc)/len(batch_acc))\n",
        "\n",
        "\n",
        "\n",
        "        # for batch_idx,_ in enumerate(valid_word_minibatches):\n",
        "        #     valid_word=valid_word_minibatches[batch_idx]\n",
        "        #     valid_label=valid_label_minibatches[batch_idx] \n",
        "        #     valid_feat=valid_feat_minibatches[batch_idx]\n",
        "\n",
        "        #     valid_word,valid_label,max_length2 = source_taget_equal_length_maker(valid_word,valid_label)\n",
        "\n",
        "        #     valid_word=torch.tensor(valid_word).to(device)\n",
        "        #     valid_label=torch.tensor(valid_label).to(device)\n",
        "        #     valid_feat=torch.FloatTensor(valid_feat).to(device)\n",
        "\n",
        "        val_loss, val_accuracy = validate_model(encoder, decoder, criteria, valid_word, valid_label, valid_feat, max_length_1,device)\n",
        "        # val_loss, val_accuracy = validate_model(encoder, decoder, None, valid_word, valid_label, valid_feat, max_length_1,device)\n",
        "        val_batch_loss.append(val_loss)\n",
        "        val_batch_acc.append(val_accuracy)\n",
        "       \n",
        "      \n",
        "      \n",
        "        print('>>>>' * 30)\n",
        "        print(\"Epoch: %d/%d\" % (epoch + 1, epoch_size),\n",
        "              \"Avg_TrainLoss: %3f\" % (sum(batch_loss) / len(batch_loss)),\n",
        "              \"Avg_TrainAccuracy: %3f\" % (sum(batch_acc) / len(batch_acc)),\n",
        "              \"Avg_ValLoss: %3f\" % (sum(val_batch_loss) / len(val_batch_loss)),\n",
        "              \"Avg_ValAccuracy: %3f\" % (sum(val_batch_acc) / len(val_batch_acc)),)\n",
        "        print('<<<<' * 30)\n",
        "\n",
        "        val_return_batch_acc.append(sum(val_batch_acc)/len(val_batch_acc))\n",
        "        val_return_batch_loss.append(sum(val_batch_loss)/len(val_batch_loss))\n",
        "\n",
        "    return return_batch_acc, return_batch_loss, val_return_batch_acc, val_return_batch_loss\n",
        "\n",
        "\"\"\"**Actual Code Starts**\"\"\"\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "words_list, inflection_list, feature_list, char_to_index, index_to_char, feature_to_index, max_word_length, max_inflection_length, max_feature_length = file_preprocess(file_name)\n",
        "\n",
        "words_list      = boundary_appender(words_list)\n",
        "inflection_list = boundary_appender(inflection_list)\n",
        "\n",
        "word_encode_list  = sentence_encoder(words_list, char_to_index)\n",
        "inf_encode_list   = sentence_encoder(inflection_list, char_to_index)\n",
        "feat_encode_list  = sentence_pad(sentence_encoder(feature_list, feature_to_index), max_feature_length)\n",
        "\n",
        "\n",
        "test_words_list, test_inflection_list, test_feature_list, _, _, _, _, _, _ = file_preprocess(evaluate_file)\n",
        "t_word_list       = boundary_appender(test_words_list)\n",
        "t_inflection_list = boundary_appender(test_inflection_list)\n",
        "\n",
        "test_word_encode_list = sentence_encoder(t_word_list, char_to_index)\n",
        "test_inf_encode_list  = sentence_encoder(t_inflection_list, char_to_index)\n",
        "test_feat_encode_list = sentence_pad(sentence_encoder(test_feature_list, feature_to_index), max_feature_length)\n",
        "\n",
        "\n",
        "\"\"\"**Hyperparameters**\"\"\"\n",
        "embedding_size   = 300\n",
        "encoder_hid_dem  = 300\n",
        "decoder_hid_dem  = 3*encoder_hid_dem\n",
        "vocab_size       = len(char_to_index.keys())\n",
        "dropout          = .75\n",
        "BATCH_SIZE       = 10         \n",
        "EPOCH_SIZE       = 30\n",
        "learning_rate    = 0.00069\n",
        "encoder_bidirectional =True\n",
        "decoder_birectional   =True\n",
        "teacher_forcing_ratio = .5\n",
        "\n",
        "\n",
        "if(encoder_bidirectional):\n",
        "    decoder_input_size  =len(feat_encode_list[0]) + embedding_size+(encoder_hid_dem)*2\n",
        "    linear_input_size=embedding_size+decoder_hid_dem+(encoder_hid_dem)*2\n",
        "else:\n",
        "    decoder_input_size  =len(feat_encode_list[0]) + embedding_size+(encoder_hid_dem)*1\n",
        "    linear_input_size=embedding_size+decoder_hid_dem+(encoder_hid_dem)*1\n",
        "\n",
        "\"\"\"**Creating instances of classes**\"\"\"\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,vocab_size, embedding_size, encoder_hid_dem,decoder_hid_dem,device,encoder_bidirectional,decoder_input_size,linear_input_size,decoder_birectional,lr):\n",
        "        super().__init__()      \n",
        "        self.encoder   = EncoderLSTM(vocab_size, embedding_size, encoder_hid_dem,decoder_hid_dem,encoder_bidirectional,device).to(device)              # (58, 300, 150)\n",
        "        self.attention = Attention(encoder_hid_dem,decoder_hid_dem,encoder_bidirectional)\n",
        "        self.decoder   = DecoderLSTM(decoder_hid_dem, encoder_hid_dem, vocab_size,embedding_size,self.attention,decoder_input_size,linear_input_size,decoder_birectional,device).to(device)          # (606, 300, 58)\n",
        "        self.encoder_optimizer = torch.optim.Adam(self.encoder.parameters(), lr)\n",
        "        self.decoder_optimizer = torch.optim.Adam(self.decoder.parameters(), lr)\n",
        "\n",
        "    def train(self):\n",
        "        train_acc, train_loss, val_acc, val_loss = train_iter(self.encoder, self.decoder, word_encode_list, inf_encode_list, feat_encode_list, test_word_encode_list, test_inf_encode_list, test_feat_encode_list, device,self.encoder_optimizer,self.decoder_optimizer,batch_size=BATCH_SIZE, epoch_size=EPOCH_SIZE)\n",
        "        ploatter(loss=train_loss, acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
        "    def test_model(self,test_input_word, test_feature_words,inflection_encode_list1,device,max_word_length=25):\n",
        "        batch_size = test_input_word.size()[0]\n",
        "        initial_word = self.encoder.embedding_layer(torch.tensor(char_to_index['<sos>']).view(1, -1).to(device)).repeat(batch_size, 1, 1)\n",
        "        encoder_outputs,hidden = self.encoder(test_input_word)\n",
        "        vali_running_acc = 0.0\n",
        "        feature = test_feature_words[:, :]\n",
        "        act = torch.zeros(batch_size,max_word_length).to(device)\n",
        "        decoder_out = []\n",
        "    \n",
        "        for idx in range(max_word_length):\n",
        "            predicted_output, hidden = self.decoder(feature, hidden,initial_word,encoder_outputs)\n",
        "            topv, topi = predicted_output.topk(1)\n",
        "            bs = topi.size()[0]\n",
        "            temp2 = torch.zeros(0,1,300).to(device)\n",
        "\n",
        "            for row in range(bs):\n",
        "              index = topi[row][0].item()\n",
        "              act[row][idx] = index\n",
        "              temp = self.encoder.embedding_layer(torch.tensor(index).view(1, -1).to(device))\n",
        "              temp2 = torch.cat((temp2,temp))\n",
        "\n",
        "            initial_word = temp2\n",
        "        \n",
        "            predicted_label = torch.argmax(predicted_output, dim=1)\n",
        "\n",
        "            num_correct = (predicted_label == inflection_encode_list1[:, idx]).sum()\n",
        "            vali_running_acc += num_correct.item()\n",
        "        \n",
        "            if topi.item() == char_to_index['<eos>']:\n",
        "                break\n",
        "            elif topi.item() != char_to_index['<sos>']:\n",
        "                decoder_out.append(index_to_char[topi.item()])\n",
        "        return decoder_out, vali_running_acc / (max_word_length * batch_size)\n",
        "\n",
        "s2s = Seq2Seq(vocab_size,embedding_size,encoder_hid_dem,decoder_hid_dem,device,encoder_bidirectional,decoder_input_size,linear_input_size,decoder_birectional,learning_rate)\n",
        "\n",
        "\n",
        "#s2s = torch.load('saved.pt')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGYw8-WA9yFn",
        "outputId": "91902c14-b6cb-44a0-9ce6-e3596d97f3d0"
      },
      "source": [
        "s2s.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 1/30 Avg_TrainLoss: 2.180490 Avg_TrainAccuracy: 0.393007 Avg_ValLoss: 1.960554 Avg_ValAccuracy: 0.461538\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 2/30 Avg_TrainLoss: 1.600134 Avg_TrainAccuracy: 0.536002 Avg_ValLoss: 1.863925 Avg_ValAccuracy: 0.500000\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 3/30 Avg_TrainLoss: 1.354934 Avg_TrainAccuracy: 0.591699 Avg_ValLoss: 1.612234 Avg_ValAccuracy: 0.535385\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 4/30 Avg_TrainLoss: 1.248954 Avg_TrainAccuracy: 0.622612 Avg_ValLoss: 1.401853 Avg_ValAccuracy: 0.621538\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 5/30 Avg_TrainLoss: 1.008234 Avg_TrainAccuracy: 0.699973 Avg_ValLoss: 1.238190 Avg_ValAccuracy: 0.661538\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 6/30 Avg_TrainLoss: 0.867810 Avg_TrainAccuracy: 0.729758 Avg_ValLoss: 1.015805 Avg_ValAccuracy: 0.706154\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 7/30 Avg_TrainLoss: 0.778215 Avg_TrainAccuracy: 0.768229 Avg_ValLoss: 0.878366 Avg_ValAccuracy: 0.769231\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 8/30 Avg_TrainLoss: 0.665033 Avg_TrainAccuracy: 0.806802 Avg_ValLoss: 0.755946 Avg_ValAccuracy: 0.795385\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 9/30 Avg_TrainLoss: 0.574572 Avg_TrainAccuracy: 0.832725 Avg_ValLoss: 0.606236 Avg_ValAccuracy: 0.824615\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 10/30 Avg_TrainLoss: 0.548285 Avg_TrainAccuracy: 0.840478 Avg_ValLoss: 0.767103 Avg_ValAccuracy: 0.789231\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 11/30 Avg_TrainLoss: 0.525997 Avg_TrainAccuracy: 0.840050 Avg_ValLoss: 0.627829 Avg_ValAccuracy: 0.823077\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 12/30 Avg_TrainLoss: 0.491161 Avg_TrainAccuracy: 0.846338 Avg_ValLoss: 0.601967 Avg_ValAccuracy: 0.812308\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 13/30 Avg_TrainLoss: 0.501432 Avg_TrainAccuracy: 0.839740 Avg_ValLoss: 0.526358 Avg_ValAccuracy: 0.843077\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 14/30 Avg_TrainLoss: 0.444536 Avg_TrainAccuracy: 0.858575 Avg_ValLoss: 0.638090 Avg_ValAccuracy: 0.796923\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 15/30 Avg_TrainLoss: 0.388167 Avg_TrainAccuracy: 0.872153 Avg_ValLoss: 0.489669 Avg_ValAccuracy: 0.849231\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 16/30 Avg_TrainLoss: 0.377919 Avg_TrainAccuracy: 0.870844 Avg_ValLoss: 0.520587 Avg_ValAccuracy: 0.843077\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 17/30 Avg_TrainLoss: 0.384016 Avg_TrainAccuracy: 0.876309 Avg_ValLoss: 0.481563 Avg_ValAccuracy: 0.849231\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 18/30 Avg_TrainLoss: 0.359712 Avg_TrainAccuracy: 0.879949 Avg_ValLoss: 0.534110 Avg_ValAccuracy: 0.832308\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 19/30 Avg_TrainLoss: 0.359338 Avg_TrainAccuracy: 0.880740 Avg_ValLoss: 0.525517 Avg_ValAccuracy: 0.832308\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 20/30 Avg_TrainLoss: 0.318075 Avg_TrainAccuracy: 0.892601 Avg_ValLoss: 0.549499 Avg_ValAccuracy: 0.838462\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 21/30 Avg_TrainLoss: 0.329868 Avg_TrainAccuracy: 0.889684 Avg_ValLoss: 0.497105 Avg_ValAccuracy: 0.840000\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 22/30 Avg_TrainLoss: 0.305027 Avg_TrainAccuracy: 0.896904 Avg_ValLoss: 0.559348 Avg_ValAccuracy: 0.840000\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 23/30 Avg_TrainLoss: 0.377067 Avg_TrainAccuracy: 0.871858 Avg_ValLoss: 0.441624 Avg_ValAccuracy: 0.843077\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Epoch: 24/30 Avg_TrainLoss: 0.317732 Avg_TrainAccuracy: 0.890997 Avg_ValLoss: 0.474133 Avg_ValAccuracy: 0.849231\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3JGXOWP9z3-"
      },
      "source": [
        "torch.save(s2s.state_dict(),'saved.pt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCIaClV691Xh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd7800a-8628-4284-90f8-27083cadcf6a"
      },
      "source": [
        "test_words_list, test_inflection_lists, test_feature_list, _, _, _, _, _, _ = file_preprocess(test_file)\n",
        "\n",
        "words_list1 = boundary_appender(test_words_list)\n",
        "tempo = test_inflection_lists\n",
        "inflection_list1 = boundary_appender(tempo)\n",
        "\n",
        "word_encode_list1 = sentence_encoder(words_list1, char_to_index)\n",
        "inflection_encode_list1 = sentence_encoder(inflection_list1, char_to_index)\n",
        "\n",
        "feat_encode_list1  = sentence_pad(sentence_encoder(test_feature_list, feature_to_index), max_feature_length)\n",
        "\n",
        "\n",
        "\n",
        "final_acc = 0;\n",
        "count=0;\n",
        "for index in range(0, len(word_encode_list1)):\n",
        "    \n",
        "#     test_word = Variable(torch.tensor(word_encode_list1[index]).view(1,-1)).cuda()\n",
        "#     test_feat = Variable(torch.FloatTensor(feat_encode_list1[index]).view(1, -1)).cuda()\n",
        "#     test_label = Variable(torch.FloatTensor(inflection_encode_list1[index]).view(1, -1)).cuda()\n",
        "\n",
        "    test_word = [word_encode_list1[index]]\n",
        "    test_feat = [feat_encode_list1[index]]\n",
        "    test_label = [inflection_encode_list1[index]]\n",
        "    \n",
        "    test_word, test_label, max_len = source_taget_equal_length_maker(test_word,test_label)\n",
        "    test_word = torch.tensor(test_word).to(device)\n",
        "    test_label = torch.tensor(test_label).to(device)\n",
        "    test_feat = torch.FloatTensor(test_feat).to(device)\n",
        "\n",
        "    predic_out,ac = s2s.test_model(test_word, test_feat,test_label,device,max_len)\n",
        "    final_acc = final_acc+ac\n",
        "    if ac==1:\n",
        "      count=count+1;\n",
        "    print(index+1)\n",
        "    print('Actual    :\\t',\"\".join(test_inflection_lists[index][1:-1]))\n",
        "    print('Prediction:\\t',\"\".join(predic_out))\n",
        "    print(ac)\n",
        "    print('')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "print(final_acc/len(word_encode_list1))\n",
        "print(count)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Actual    :\t betrieget\n",
            "Prediction:\t chzv<pad>zv<pad>chw\n",
            "0.0\n",
            "\n",
            "2\n",
            "Actual    :\t engele\n",
            "Prediction:\t ch\n",
            "0.0\n",
            "\n",
            "3\n",
            "Actual    :\t burcgrâven\n",
            "Prediction:\t chwv<pad>wv<pad>aoëh\n",
            "0.0\n",
            "\n",
            "4\n",
            "Actual    :\t rinnet\n",
            "Prediction:\t cwv<pad>wôwu\n",
            "0.0\n",
            "\n",
            "5\n",
            "Actual    :\t wahse\n",
            "Prediction:\t câpoiwôw\n",
            "0.0\n",
            "\n",
            "6\n",
            "Actual    :\t trinken\n",
            "Prediction:\t chwôwv<pad>ao\n",
            "0.0\n",
            "\n",
            "7\n",
            "Actual    :\t rinnet\n",
            "Prediction:\t chwuiwv<pad>\n",
            "0.0\n",
            "\n",
            "8\n",
            "Actual    :\t hülfen\n",
            "Prediction:\t c<pad>zv<pad>pv<pad>\n",
            "0.0\n",
            "\n",
            "9\n",
            "Actual    :\t betrieget\n",
            "Prediction:\t chwuinphwv<pad>\n",
            "0.0\n",
            "\n",
            "10\n",
            "Actual    :\t swimme\n",
            "Prediction:\t chwv<pad>wsei\n",
            "0.1111111111111111\n",
            "\n",
            "11\n",
            "Actual    :\t wahsen\n",
            "Prediction:\t chwvpv<pad>w\n",
            "0.0\n",
            "\n",
            "12\n",
            "Actual    :\t göu\n",
            "Prediction:\t ch\n",
            "0.0\n",
            "\n",
            "13\n",
            "Actual    :\t vinden\n",
            "Prediction:\t chwgaozv\n",
            "0.0\n",
            "\n",
            "14\n",
            "Actual    :\t göugrâven\n",
            "Prediction:\t chzv<pad>iozv<pad>w\n",
            "0.0\n",
            "\n",
            "15\n",
            "Actual    :\t enpfind\n",
            "Prediction:\t chwuiwôhwv<pad>\n",
            "0.09090909090909091\n",
            "\n",
            "16\n",
            "Actual    :\t swüren\n",
            "Prediction:\t zv<pad>zvpv<pad>\n",
            "0.0\n",
            "\n",
            "17\n",
            "Actual    :\t swimmet\n",
            "Prediction:\t chwgôwv<pad><pad>\n",
            "0.1111111111111111\n",
            "\n",
            "18\n",
            "Actual    :\t hëlfende\n",
            "Prediction:\t chwv<pad>lôhwv\n",
            "0.1\n",
            "\n",
            "19\n",
            "Actual    :\t göuwe\n",
            "Prediction:\t chwv<pad>wv\n",
            "0.0\n",
            "\n",
            "20\n",
            "Actual    :\t grâven\n",
            "Prediction:\t zvpv<pad>wv<pad>\n",
            "0.0\n",
            "\n",
            "21\n",
            "Actual    :\t küse\n",
            "Prediction:\t chwv<pad>wôw\n",
            "0.0\n",
            "\n",
            "22\n",
            "Actual    :\t küse\n",
            "Prediction:\t cwuioozv\n",
            "0.0\n",
            "\n",
            "23\n",
            "Actual    :\t verswinde\n",
            "Prediction:\t chwôëwv<pad>aooz\n",
            "0.08333333333333333\n",
            "\n",
            "24\n",
            "Actual    :\t vindet\n",
            "Prediction:\t r\n",
            "0.0\n",
            "\n",
            "25\n",
            "Actual    :\t kiesest\n",
            "Prediction:\t chwv<pad>wseh\n",
            "0.1111111111111111\n",
            "\n",
            "26\n",
            "Actual    :\t siedent\n",
            "Prediction:\t cwv<pad>pv<pad>cô\n",
            "0.0\n",
            "\n",
            "27\n",
            "Actual    :\t geswummen\n",
            "Prediction:\t ch\n",
            "0.0\n",
            "\n",
            "28\n",
            "Actual    :\t sweren\n",
            "Prediction:\t cwv<pad>wv<pad><pad>\n",
            "0.0\n",
            "\n",
            "29\n",
            "Actual    :\t trugen\n",
            "Prediction:\t chwv<pad><pad>wvs\n",
            "0.0\n",
            "\n",
            "30\n",
            "Actual    :\t wërdet\n",
            "Prediction:\t chwv<pad><pad><pad>w\n",
            "0.0\n",
            "\n",
            "31\n",
            "Actual    :\t verswinden\n",
            "Prediction:\t cwv<pad>ücwuiwâf\n",
            "0.0\n",
            "\n",
            "32\n",
            "Actual    :\t verswindende\n",
            "Prediction:\t chwv<pad>hwuiwuin\n",
            "0.0\n",
            "\n",
            "33\n",
            "Actual    :\t beginnen\n",
            "Prediction:\t chwuiaoôwu\n",
            "0.1\n",
            "\n",
            "34\n",
            "Actual    :\t wurden\n",
            "Prediction:\t cwv<pad>wv<pad>w\n",
            "0.125\n",
            "\n",
            "35\n",
            "Actual    :\t betriegen\n",
            "Prediction:\t cwôwôwgôlzü\n",
            "0.0\n",
            "\n",
            "36\n",
            "Actual    :\t bindet\n",
            "Prediction:\t chwv<pad>zvs\n",
            "0.0\n",
            "\n",
            "37\n",
            "Actual    :\t kieset\n",
            "Prediction:\t chwuiozv\n",
            "0.0\n",
            "\n",
            "38\n",
            "Actual    :\t bieget\n",
            "Prediction:\t chwuipv<pad>\n",
            "0.0\n",
            "\n",
            "39\n",
            "Actual    :\t wahse\n",
            "Prediction:\t chwgrgôw\n",
            "0.0\n",
            "\n",
            "40\n",
            "Actual    :\t kôs\n",
            "Prediction:\t cwvseipv\n",
            "0.125\n",
            "\n",
            "41\n",
            "Actual    :\t vinde\n",
            "Prediction:\t chwv<pad>wv<pad>\n",
            "0.125\n",
            "\n",
            "42\n",
            "Actual    :\t wüehse\n",
            "Prediction:\t cwâpv<pad>aö\n",
            "0.125\n",
            "\n",
            "43\n",
            "Actual    :\t binden\n",
            "Prediction:\t ch\n",
            "0.0\n",
            "\n",
            "44\n",
            "Actual    :\t swuor\n",
            "Prediction:\t chwâpia\n",
            "0.14285714285714285\n",
            "\n",
            "45\n",
            "Actual    :\t begünne\n",
            "Prediction:\t câpv<pad><pad>âwôw\n",
            "0.0\n",
            "\n",
            "46\n",
            "Actual    :\t rinnest\n",
            "Prediction:\t chwseiwoi\n",
            "0.0\n",
            "\n",
            "47\n",
            "Actual    :\t warf\n",
            "Prediction:\t chwv<pad>wôs\n",
            "0.0\n",
            "\n",
            "48\n",
            "Actual    :\t trunken\n",
            "Prediction:\t chwuiwuiw\n",
            "0.1111111111111111\n",
            "\n",
            "49\n",
            "Actual    :\t bügen\n",
            "Prediction:\t chwuiozü\n",
            "0.0\n",
            "\n",
            "50\n",
            "Actual    :\t göuwen\n",
            "Prediction:\t chwvpvpv\n",
            "0.0\n",
            "\n",
            "0.02923088023088023\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvJ0LVv692r2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}